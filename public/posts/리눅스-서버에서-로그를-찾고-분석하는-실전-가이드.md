# 리눅스 서버에서 로그를 찾고 분석하는 실전 가이드

---

리눅스 서버를 운영하다 보면 문제가 생겼을 때 가장 먼저 해야 할 일이 뭘까요? 바로 **로그 파일을 확인하는 것** 입니다. 서버의 상태를 파악하고, 에러의 원인을 찾고, 성능 문제를 진단하는 모든 과정이 로그에서 시작돼요. 하지만 로그 파일은 보통 엄청 크고, 필요한 정보를 찾기가 쉽지 않습니다.

이 글에서는 실무에서 정말 자주 쓰는 리눅스 명령어들을 초급자 눈높이에 맞춰 정리했어요. 로그 파일을 찾는 것부터 시작해서, 특정 정보를 검색하고, 실시간으로 모니터링하는 방법까지 모두 다룹니다. 이 명령어들을 익히면 서버 문제가 생겼을 때 훨씬 빠르게 대응할 수 있을 거예요.

---

**📂 첫 번째 단계: 최신 로그 파일 찾기**

서버에서 로그를 확인하려면 먼저 로그 파일이 어디에 있는지 찾아야 합니다. 특히 여러 날짜의 로그 파일이 있을 때, 가장 최신 파일을 빠르게 찾는 것이 중요해요.

이때 사용하는 명령어가 ll -ltr입니다. 여기서 ll은 ls -l의 축약형이고, 옵션 -t는 파일을 수정 시간 순으로 정렬하고, -r은 역순(가장 최신이 맨 아래)으로 표시합니다.​

이 명령어를 실행하면 /var/log/tomcat/ 디렉토리의 모든 파일이 수정 시간 순으로 나열됩니다. 맨 아래에 있는 파일이 가장 최신 파일이에요. 파일의 권한, 소유자, 수정 날짜까지 한눈에 볼 수 있어서 정말 유용합니다.

💡 **팁:** 로그 파일이 너무 많으면 tail과 함께 사용하세요. ll -ltr /var/log/tomcat/ | tail -10이라고 하면 가장 최신 10개 파일만 볼 수 있어요.

---

**🔎 두 번째 단계: 특정 키워드로 로그 검색하기**

로그 파일을 찾았다면, 이제 그 안에서 필요한 정보를 찾아야 합니다. 로그 파일은 보통 수천 줄, 수만 줄이 있기 때문에 직접 다 읽을 수 없어요. 이때 사용하는 것이 grep 명령어입니다.

grep은 파일에서 특정 패턴을 포함한 라인만 찾아서 보여줍니다. 예를 들어, "ERROR"라는 단어가 들어간 모든 라인을 찾고 싶다면:​

또는 cat​

두 방식은 같은 결과를 줍니다. 파이프(|)를 사용한 두 번째 방식은 여러 명령어를 연결할 때 유연해요.

**grep의 유용한 옵션들**

예를 들어, 특정 사용자의 로그인 시도를 찾고 싶다면:

이 명령어는 userId=12345를 포함하는 모든 라인을 라인 번호와 함께 보여줍니다. 라인 번호가 있으면 나중에 파일을 열어서 그 부분을 쉽게 찾을 수 있어요.

---

**📖 세 번째 단계: less로 대용량 로그 파일 탐색하기**

로그 파일이 너무 크면 catless 명령어입니다.

lessmore라는 비슷한 명령어도 있지만, less

**less vs more: 왜 less를 써야 할까?**

more는 다음과 같은 단점들이 있어요:

  * **역방향 스크롤 불가능:** more는 위로 올라갈 수 없습니다. 한 번 지나가면 다시 처음부터 읽어야 해요.

  * **검색 기능 부족:** 특정 단어를 찾는 기능이 없어서 원하는 부분을 찾기 어렵습니다.

  * **추가 기능 부족:** 파일의 특정 위치로 이동하거나 라인 번호를 보는 등의 기능이 없습니다.

  * **상호작용성 부족:** 사용자가 할 수 있는 작업이 매우 제한적입니다.

반면 less

예를 들어, catalina.log 파일을 열어서 "NullPointerException"이라는 에러를 찾고 싶다면:

정리하자면, less

---

**⚡ 네 번째 단계: tail로 실시간 로그 모니터링하기**

서버에 문제가 생겼을 때, 실시간으로 로그를 봐야 할 경우가 많습니다. 이때 tail 명령어가 정말 유용해요. tail-f 옵션을 사용하면 파일이 업데이트될 때마다 새로운 내용을 자동으로 출력합니다.

이 명령어를 실행하면, 로그 파일의 마지막 10줄이 보이고, 그 이후로 새로 추가되는 모든 내용이 실시간으로 화면에 나타납니다. 서버가 처리하는 요청들을 실시간으로 모니터링할 수 있어요.

💡 **중요한 팁:** vi나 less로 파일을 열어서 읽기 전용으로 보면, 애플리케이션이 로그를 계속 기록하지 못할 수 있습니다. 하지만 tail -f

**특정 키워드만 실시간으로 모니터링하기**

로그에 ERROR가 많으면, ERROR만 보고 싶을 수도 있어요. 이때는 tailgrep

이 명령어는 로그 파일에서 ERROR를 포함하는 라인만 실시간으로 보여줍니다. 서버에 문제가 생겼을 때 에러만 집중해서 볼 수 있어요.

tail -fCtrl + C를 누르면 됩니다.

---

**🛠️ 다섯 번째 단계: awk로 필드 추출하기**

로그를 검색한 후, 그 결과에서 특정 부분만 추출하고 싶을 때가 있어요. 예를 들어, 로그에서 사용자 ID만 뽑아내거나, 특정 시간대의 요청만 분석하고 싶을 수 있습니다. 이때 사용하는 것이 awk 명령어입니다.

awk

다음과 같은 로그 라인이 있다고 가정해봅시다:

이 라인에서 각 부분이 필드입니다:

  * **$1:** 2024-08-30 (첫 번째 필드)

  * **$2:** 12:34:56 (두 번째 필드)

  * **$3:** INFO (세 번째 필드)

  * **$4:** userId=12345 (네 번째 필드)

  * **$5:** action=login (다섯 번째 필드)

  * **$6:** status=success (여섯 번째 필드)

만약 이 로그에서 사용자 ID만 뽑아내고 싶다면:

이 명령어는 userId=를 포함하는 모든 라인에서 네 번째 필드(userId=12345)만 출력합니다.

또는 시간과 사용자 ID만 보고 싶다면:

이렇게 하면 시간과 사용자 ID가 함께 출력됩니다. awk

---

**🔎 여섯 번째 단계: find로 로그 파일 찾기**

때로는 로그 파일이 어디에 있는지 모를 때가 있어요. 특히 새로운 서버에 접속했거나, 설정을 모를 때 말이죠. 이때 사용하는 것이 find 명령어입니다.

이 명령어는 /app/logs/ 디렉토리 내에서 "tsolution.2024-07"로 시작하는 모든 파일을 찾습니다. 와일드카드(*)를 사용해서 부분적으로 파일명을 지정할 수 있어요.

더 넓은 범위에서 찾고 싶다면:

이 명령어는 루트 디렉토리(/)부터 시작해서 catalina.log라는 파일을 모두 찾습니다. 2>/dev/null은 에러 메시지를 무시하라는 뜻이에요. 권한이 없는 디렉토리에서 나오는 에러들을 보지 않을 수 있습니다.

정리하자면, find

---

**💼 실무에서 자주 쓰는 명령어 조합**

지금까지 배운 명령어들을 조합하면 더욱 강력한 분석이 가능합니다. 실무에서 자주 사용하는 패턴들을 소개할게요.

**1️⃣ 특정 시간대의 에러만 찾기**

이 명령어는 2024-08-30 14시대의 ERROR만 찾습니다. 특정 시간대에 뭔가 문제가 있었다면 이렇게 좁혀서 찾을 수 있어요.

**2️⃣ 특정 사용자의 모든 활동 추적하기**

이 명령어는 특정 사용자의 모든 활동을 시간과 함께 보여줍니다. 사용자가 뭘 했는지 추적할 수 있어요.

**3️⃣ 에러의 종류별로 개수 세기**

이 명령어는 어떤 종류의 Exception이 몇 번 발생했는지 보여줍니다. 가장 많이 발생하는 에러부터 순서대로 나열돼요.

**4️⃣ 최신 로그 파일을 실시간으로 모니터링하기**

이 명령어는 가장 최신 로그 파일을 자동으로 찾아서 실시간으로 모니터링합니다. 여러 로그 파일이 있을 때 정말 유용해요.

---

**🎯 초급자가 꼭 기억해야 할 팁들**

**1\. grep과 tail의 차이를 이해하세요**

grep은 파일 전체에서 특정 패턴을 찾는 것이고, tail은 파일의 끝부분을 보거나 실시간으로 모니터링하는 것입니다. 상황에 따라 올바른 명령어를 선택해야 해요.

**2\. 파이프(|)를 적극 활용하세요**

여러 명령어를 파이프로 연결하면 매우 강력한 분석이 가능합니다. grep으로 필터링하고, awk로 필드를 추출하고, sort로 정렬하는 식으로 조합할 수 있어요.

**3\. 대소문자를 주의하세요**

grep은 기본적으로 대소문자를 구분합니다. ERROR와 error는 다르다고 봐요. 확실하지 않으면 -i 옵션을 사용해서 대소문자를 무시하는 게 좋습니다.

**4\. 로그 파일이 너무 크면 분할해서 봅시다**

로그 파일이 수 GB 이상이면, 전체를 한 번에 처리하기 어려워요. grep으로 먼저 필터링해서 작은 파일로 만든 후 분석하는 게 좋습니다.

**5\. 백업을 항상 생각하세요**

로그 분석을 하다가 실수로 파일을 수정하면 안 돼요. 읽기 전용으로 열거나, 복사본을 만들어서 작업하는 게 안전합니다.

---

**🎓 마치며**

리눅스 서버에서 로그를 확인하고 분석하는 것은 개발자의 기본 스킬입니다. 처음에는 어려워 보일 수 있지만, 이 글에서 배운 명령어들을 자주 사용하다 보면 자연스럽게 익혀질 거예요.

​

가장 중요한 것은 **상황에 맞는 올바른 도구를 선택하는 것** 입니다. 

빠르게 검색하고 싶으면 grep, 

대용량 파일을 탐색하고 싶으면 less, 

실시간 모니터링이 필요하면 tail을 사용하세요. 

​

이 명령어들을 능숙하게 다루면, 서버 문제가 생겼을 때 훨씬 빠르게 원인을 찾고 대응할 수 있을 거예요.

​

처음에는 한 번에 하나씩 배우고, 점차 여러 명령어를 조합해서 사용해 보세요. 

실무에서 자주 쓰는 패턴들을 자신만의 스크립트로 만들어 두면 더욱 효율적입니다. 화이팅! 🚀

​

#리눅스 #로그분석 #grep #tail #less #awk #서버운영 #명령어

[원문 보기](https://blog.naver.com/choidz_/224108722372?fromRss=true&trackingCode=rss)
